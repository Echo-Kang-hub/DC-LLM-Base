"""
å®éªŒ1ï¼šå¸¦å¼•ç”¨æ ‡æ³¨çš„RAGé—®ç­”
é€šè¿‡ä¿®æ”¹Promptè®©LLMåœ¨å›ç­”æ—¶æ ‡æ³¨å¼•ç”¨æ¥æº
"""

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from config import Config
from vector_store_manager import VectorStoreManager
from document_processor import DocumentProcessor


def rag_with_citation(query, vectorstore, client):
    """å¸¦å¼•ç”¨æ ‡æ³¨çš„RAGé—®ç­”
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        vectorstore: å‘é‡å­˜å‚¨å®ä¾‹
        client: ChatOpenAIå®¢æˆ·ç«¯
        
    Returns:
        answer: LLMç”Ÿæˆçš„å›ç­”
        retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
    """
    # ç¬¬1æ­¥ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£
    retrieved_docs = vectorstore.similarity_search(query, k=5)

    # ç¬¬2æ­¥ï¼šæ„å»ºå¸¦ç¼–å·çš„ä¸Šä¸‹æ–‡
    context_parts = []
    for i, doc in enumerate(retrieved_docs, 1):
        context_parts.append(f"[æ–‡æ¡£{i}] {doc.page_content}")
    context = "\n\n".join(context_parts)

    # ç¬¬3æ­¥ï¼šç”¨å¸¦å¼•ç”¨è¦æ±‚çš„Promptç”Ÿæˆå›ç­”
    prompt = f"""åŸºäºä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. å›ç­”ä¸­çš„æ¯ä¸ªå…³é”®ä¿¡æ¯ç‚¹éƒ½å¿…é¡»æ ‡æ³¨å¼•ç”¨æ¥æºï¼Œæ ¼å¼ä¸º[æ–‡æ¡£X]
2. å¦‚æœæŸä¸ªä¿¡æ¯æ¥è‡ªå¤šä¸ªæ–‡æ¡£ï¼Œæ ‡æ³¨æ‰€æœ‰ç›¸å…³æ–‡æ¡£ï¼Œå¦‚[æ–‡æ¡£1][æ–‡æ¡£3]
3. å¦‚æœå‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜"æ ¹æ®ç°æœ‰èµ„æ–™æ— æ³•å›ç­”"
4. ä¸è¦ç¼–é€ å‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯

å‚è€ƒæ–‡æ¡£ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·å›ç­”ï¼ˆè®°å¾—æ ‡æ³¨å¼•ç”¨ï¼‰ï¼š"""

    # ä½¿ç”¨LangChainçš„invokeæ–¹æ³•è°ƒç”¨LLM
    response = client.invoke([HumanMessage(content=prompt)])
    answer = response.content

    # ç¬¬4æ­¥ï¼šå±•ç¤ºå›ç­”å’Œå¼•ç”¨æ¥æº
    print("=" * 60)
    print(f"é—®é¢˜ï¼š{query}\n")
    print(f"å›ç­”ï¼š{answer}\n")
    print("å¼•ç”¨æ¥æºï¼š")
    for i, doc in enumerate(retrieved_docs, 1):
        print(f"  [æ–‡æ¡£{i}] {doc.page_content[:100]}...")
    print("=" * 60)

    return answer, retrieved_docs


def run_citation_experiment():
    """è¿è¡Œå¼•ç”¨æ ‡æ³¨å®éªŒ"""
    print("\n" + "="*80)
    print("ğŸ”¬ å®éªŒ1: å¸¦å¼•ç”¨æ ‡æ³¨çš„RAGé—®ç­”")
    print("="*80)
    
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
    print("\nğŸ“š åŠ è½½å‘é‡å­˜å‚¨...")
    vector_store_manager = VectorStoreManager()
    vector_store_manager.load_vector_store()
    vectorstore = vector_store_manager.vector_store
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    print("ğŸ¤– åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
    client = ChatOpenAI(
        model=Config.OPENAI_MODEL,
        temperature=0,
        openai_api_key=Config.OPENAI_API_KEY,
        openai_api_base=Config.OPENAI_API_BASE
    )
    
    # æµ‹è¯•é—®é¢˜åˆ—è¡¨
    test_questions = [
        "æ¯”äºšè¿ªæµ·è±¹çš„ç”µæ± å®¹é‡æ˜¯å¤šå°‘ï¼Ÿ",
        "é¢†å…‹çš„åº§ä½é…ç½®æ˜¯æ€æ ·çš„ï¼Ÿ",
        "ç‰¹æ–¯æ‹‰Model Yçš„åŠ é€Ÿæ€§èƒ½å¦‚ä½•ï¼Ÿ",
        "å¦‚ä½•é€šè¿‡ä¸­å¤®æ˜¾ç¤ºå±è¿›è¡Œå‰¯é©¾é©¶å‘˜åº§æ¤…è®¾ç½®ï¼Ÿ",
        "å¦‚ä½•æ‰“å¼€è½¦è¾†å°¾é—¨ï¼Ÿ"
    ]
    
    print("\n" + "="*80)
    print("å¼€å§‹æµ‹è¯•å¸¦å¼•ç”¨æ ‡æ³¨çš„RAGé—®ç­”")
    print("="*80 + "\n")
    
    # å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œæµ‹è¯•
    for idx, question in enumerate(test_questions, 1):
        print(f"\n{'ğŸ”¸'*40}")
        print(f"æµ‹è¯• {idx}/{len(test_questions)}")
        print(f"{'ğŸ”¸'*40}\n")
        
        answer, sources = rag_with_citation(question, vectorstore, client)
        
        # æ·»åŠ å»¶æ—¶é¿å…APIé™æµ
        if idx < len(test_questions):
            import time
            time.sleep(1)
    
    print("\n" + "="*80)
    print("âœ… å®éªŒå®Œæˆï¼")
    print("="*80)


def interactive_citation_mode():
    """äº¤äº’å¼å¸¦å¼•ç”¨é—®ç­”æ¨¡å¼"""
    print("\n" + "="*80)
    print("ğŸ’¬ äº¤äº’å¼å¸¦å¼•ç”¨é—®ç­”æ¨¡å¼")
    print("="*80)
    print("æç¤ºï¼šè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")
    
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
    print("ğŸ“š åŠ è½½å‘é‡å­˜å‚¨...")
    vector_store_manager = VectorStoreManager()
    vector_store_manager.load_vector_store()
    vectorstore = vector_store_manager.vector_store
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    print("ğŸ¤– åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...\n")
    client = ChatOpenAI(
        model=Config.OPENAI_MODEL,
        temperature=0,
        openai_api_key=Config.OPENAI_API_KEY,
        openai_api_base=Config.OPENAI_API_BASE
    )
    
    print("å‡†å¤‡å°±ç»ªï¼è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š\n")
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input("ğŸ‘¤ æ‚¨çš„é—®é¢˜: ").strip()
            
            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            # è·³è¿‡ç©ºè¾“å…¥
            if not user_input:
                continue
            
            # è°ƒç”¨å¸¦å¼•ç”¨çš„RAGé—®ç­”
            print()
            answer, sources = rag_with_citation(user_input, vectorstore, client)
            print()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}\n")


if __name__ == "__main__":
    import sys
    
    # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "interactive":
        interactive_citation_mode()
    else:
        run_citation_experiment()
