import json
import time
import pandas as pd
from typing import List, Dict, Any
from datetime import datetime

from config import Config
from document_processor import DocumentProcessor
from vector_store_manager import VectorStoreManager
from rag_chain import RAGChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate


class RAGExperiments:
    def __init__(self):
        self.knowledge_base_path = Config.KNOWLEDGE_BASE_PATH
        self.test_questions_path = 'test_question.json'
        self.results = []
        
    # åŠ è½½æµ‹è¯•é—®é¢˜
    def load_test_questions(self, limit=10) -> List[Dict]:
        with open(self.test_questions_path, 'r', encoding='utf-8') as f:
            questions = json.load(f)
        return questions[:limit]
    
    # ==================== å®éªŒ1: Chunk Sizeå¯¹æ¯” ====================
    
    # å®éªŒ1ï¼šæµ‹è¯•ä¸åŒçš„Chunk Sizeå¯¹æ£€ç´¢æ•ˆæœçš„å½±å“
    def experiment_chunk_size(self):
        print("\n" + "="*60)
        print("ğŸ”¬ å®éªŒ1: Chunk Sizeå¯¹æ¯”å®éªŒ")
        print("="*60)
        
        chunk_sizes = [256,512,1024]
        test_questions = self.load_test_questions(limit=5)
        results = []
        
        for chunk_size in chunk_sizes:
            print(f"\nğŸ“ æµ‹è¯• Chunk Size = {chunk_size}")
            print("-" * 60)
            
            # é‡æ–°å¤„ç†æ–‡æ¡£
            doc_processor = DocumentProcessor(
                chunk_size=chunk_size,
                chunk_overlap=50
            )
            splits = doc_processor.process_pdf(self.knowledge_base_path)
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            vector_store_manager = VectorStoreManager()
            vector_store_manager.create_vector_store(splits)
            
            # åˆ›å»ºRAGé“¾
            rag_chain = RAGChain(vector_store_manager)
            
            # æµ‹è¯•æ¯ä¸ªé—®é¢˜
            for q in test_questions:
                question = q['question']
                start_time = time.time()
                
                try:
                    response = rag_chain.get_answer_with_sources(question)
                    answer = response['answer']
                    num_sources = len(response['sources'])
                    response_time = time.time() - start_time
                    
                    result = {
                        'chunk_size': chunk_size,
                        'question': question,
                        'answer': answer,
                        'num_sources': num_sources,
                        'response_time': response_time,
                        'num_chunks': len(splits)
                    }
                    results.append(result)
                    
                    print(f"  âœ“ {question[:30]}... ({response_time:.2f}s)")
                    
                except Exception as e:
                    print(f"  âœ— {question[:30]}... å¤±è´¥: {e}")
        
        # ä¿å­˜ç»“æœ
        df = pd.DataFrame(results)
        output_file = f'experiment_chunk_size_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        self._print_chunk_size_summary(df)
        
        return df
    
    def _print_chunk_size_summary(self, df):
        """æ‰“å°Chunk Sizeå®éªŒæ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
        print("="*60)
        
        summary = df.groupby('chunk_size').agg({
            'response_time': 'mean',
            'num_chunks': 'first'
        }).round(2)
        
        print(summary)
        print(f"\nğŸ’¡ å»ºè®®ï¼šé€‰æ‹©å“åº”æ—¶é—´å’Œå‡†ç¡®åº¦å¹³è¡¡çš„chunk_size")
    
    # ==================== å®éªŒ2: Re-ranking (é‡æ’åº) ====================
    
    def experiment_reranking(self, use_best_chunk_size=True):
        """
        å®éªŒ2ï¼šæµ‹è¯•Re-rankingå¯¹æ£€ç´¢ç»“æœçš„ä¼˜åŒ–
        æ–¹æ³•ï¼šä½¿ç”¨LLMå¯¹æ£€ç´¢ç»“æœè¿›è¡Œç›¸å…³æ€§é‡æ’åºï¼ˆé‡‡ç”¨é€ä¸ªè¯„åˆ†æ–¹æ³•ï¼‰
        
        Args:
            use_best_chunk_size: æ˜¯å¦ä½¿ç”¨æœ€ä½³chunk_size=1024é‡å»ºå‘é‡åº“
        """
        print("\n" + "="*60)
        print("ğŸ”¬ å®éªŒ2: Re-ranking (é‡æ’åº) å®éªŒ")
        print("="*60)
        
        # å¦‚æœéœ€è¦ä½¿ç”¨æœ€ä½³chunk_sizeï¼Œå…ˆé‡å»ºå‘é‡åº“
        if use_best_chunk_size:
            print("\nğŸ“ ä½¿ç”¨æœ€ä½³ Chunk Size = 1024 é‡å»ºå‘é‡åº“")
            doc_processor = DocumentProcessor(chunk_size=1024, chunk_overlap=200)
            splits = doc_processor.process_pdf(self.knowledge_base_path)
            vector_store_manager = VectorStoreManager()
            vector_store_manager.create_vector_store(splits)
        else:
            # åŠ è½½ç°æœ‰å‘é‡å­˜å‚¨
            vector_store_manager = VectorStoreManager()
            vector_store_manager.load_vector_store()
        
        # åˆå§‹åŒ–LLMç”¨äºé‡æ’åº
        llm = ChatOpenAI(
            model=Config.OPENAI_MODEL,
            temperature=0,  # æ¸©åº¦=0ç¡®ä¿è¯„åˆ†ç¨³å®š
            openai_api_key=Config.OPENAI_API_KEY,
            openai_api_base=Config.OPENAI_API_BASE
        )
        
        test_questions = self.load_test_questions(limit=5)
        results = []
        
        for q in test_questions:
            question = q['question']
            print(f"\nâ“ é—®é¢˜: {question}")
            print("-" * 60)
            
            # 1. æ™®é€šæ£€ç´¢ (k=10)
            start_time = time.time()
            docs_original = vector_store_manager.similarity_search(question, k=10)
            time_original = time.time() - start_time
            
            # 2. ä½¿ç”¨LLMè¿›è¡ŒRe-rankingï¼ˆé‡‡ç”¨è€å¸ˆçš„é€ä¸ªè¯„åˆ†æ–¹æ³•ï¼‰
            start_time = time.time()
            docs_reranked = self._rerank_documents_teacher_method(question, docs_original, llm, top_k=3)
            time_reranked = time.time() - start_time
            
            # 3. åˆ†åˆ«ç”Ÿæˆç­”æ¡ˆ
            rag_chain = RAGChain(vector_store_manager)
            
            # ä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ
            answer_original = self._get_answer_from_docs(question, docs_original[:4], llm)
            
            # ä½¿ç”¨é‡æ’åºç»“æœ
            answer_reranked = self._get_answer_from_docs(question, docs_reranked, llm)
            
            result = {
                'question': question,
                'answer_original': answer_original,
                'answer_reranked': answer_reranked,
                'time_original': time_original,
                'time_reranked': time_reranked,
                'docs_changed': self._docs_order_changed(docs_original[:4], docs_reranked)
            }
            results.append(result)
            
            print(f"  åŸå§‹æ£€ç´¢: {time_original:.2f}s")
            print(f"  é‡æ’åºå: {time_reranked:.2f}s")
            print(f"  æ–‡æ¡£é¡ºåºå˜åŒ–: {result['docs_changed']}")
        
        # ä¿å­˜ç»“æœ
        df = pd.DataFrame(results)
        output_file = f'experiment_reranking_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return df
    
    def _rerank_documents(self, query: str, documents: List, llm, top_k: int = 4) -> List:
        """ä½¿ç”¨LLMå¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº"""
        
        # åˆ›å»ºé‡æ’åºæç¤º
        rerank_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œç»™æ¯ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§æ‰“åˆ†(0-10åˆ†)ã€‚
åªè¾“å‡ºJSONæ ¼å¼ï¼š[{{"doc_id": 0, "score": 8}}, {{"doc_id": 1, "score": 5}}, ...]"""),
            ("human", """é—®é¢˜: {question}

æ–‡æ¡£åˆ—è¡¨:
{documents}

è¯·è¯„åˆ†ï¼š""")
        ])
        
        # å‡†å¤‡æ–‡æ¡£åˆ—è¡¨
        docs_text = ""
        for i, doc in enumerate(documents):
            docs_text += f"\næ–‡æ¡£ {i}:\n{doc.page_content[:200]}...\n"
        
        # è°ƒç”¨LLMè¯„åˆ†
        try:
            chain = rerank_prompt | llm
            response = chain.invoke({
                "question": query,
                "documents": docs_text
            })
            
            # è§£æåˆ†æ•°
            import re
            scores_text = response.content
            # ç®€å•çš„å¯å‘å¼è§£æï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ›´å¥å£®çš„æ–¹æ³•ï¼‰
            scores = []
            for i in range(len(documents)):
                # æŸ¥æ‰¾æ¯ä¸ªæ–‡æ¡£çš„åˆ†æ•°
                pattern = f'"doc_id":\\s*{i}[^0-9]*"score":\\s*(\\d+)'
                match = re.search(pattern, scores_text)
                if match:
                    scores.append((i, int(match.group(1))))
                else:
                    scores.append((i, 0))
            
            # æŒ‰åˆ†æ•°æ’åº
            scores.sort(key=lambda x: x[1], reverse=True)
            
            # è¿”å›é‡æ’åºçš„æ–‡æ¡£
            reranked_docs = [documents[doc_id] for doc_id, _ in scores[:top_k]]
            return reranked_docs
            
        except Exception as e:
            print(f"  âš ï¸  é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹é¡ºåº: {e}")
            return documents[:top_k]
    
    def _get_answer_from_docs(self, question: str, docs: List, llm) -> str:
        """æ ¹æ®ç»™å®šæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ"""
        context = "\n\n".join([doc.page_content for doc in docs])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n\nä¸Šä¸‹æ–‡:\n{context}"),
            ("human", "{question}")
        ])
        
        chain = prompt | llm
        response = chain.invoke({"context": context, "question": question})
        return response.content
    
    def _docs_order_changed(self, docs1: List, docs2: List) -> bool:
        """æ£€æŸ¥æ–‡æ¡£é¡ºåºæ˜¯å¦æ”¹å˜"""
        if len(docs1) != len(docs2):
            return True
        for i in range(len(docs1)):
            if docs1[i].page_content != docs2[i].page_content:
                return True
        return False
    
    # ==================== å®éªŒ3: Query Rewriting (æŸ¥è¯¢æ”¹å†™) ====================
    
    def experiment_query_rewriting(self):
        """
        å®éªŒ3ï¼šæµ‹è¯•Query Rewritingå¯¹æ£€ç´¢æ•ˆæœçš„æå‡
        æ–¹æ³•ï¼šä½¿ç”¨LLMæ”¹å†™ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿å…¶æ›´é€‚åˆæ£€ç´¢
        """
        print("\n" + "="*60)
        print("ğŸ”¬ å®éªŒ3: Query Rewriting (æŸ¥è¯¢æ”¹å†™) å®éªŒ")
        print("="*60)
        
        # åŠ è½½å‘é‡å­˜å‚¨
        vector_store_manager = VectorStoreManager()
        vector_store_manager.load_vector_store()
        
        # åˆå§‹åŒ–LLM
        llm = ChatOpenAI(
            model=Config.OPENAI_MODEL,
            temperature=0.3,
            openai_api_key=Config.OPENAI_API_KEY,
            openai_api_base=Config.OPENAI_API_BASE
        )
        
        test_questions = self.load_test_questions(limit=5)
        results = []
        
        for q in test_questions:
            original_question = q['question']
            print(f"\nâ“ åŸå§‹é—®é¢˜: {original_question}")
            print("-" * 60)
            
            # 1. æ”¹å†™æŸ¥è¯¢
            rewritten_queries = self._rewrite_query(original_question, llm)
            print(f"  æ”¹å†™å:")
            for i, rq in enumerate(rewritten_queries, 1):
                print(f"    {i}. {rq}")
            
            # 2. ä½¿ç”¨åŸå§‹é—®é¢˜æ£€ç´¢
            start_time = time.time()
            docs_original = vector_store_manager.similarity_search(original_question, k=5)
            time_original = time.time() - start_time
            answer_original = self._get_answer_from_docs(original_question, docs_original, llm)
            
            # 3. ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢æ£€ç´¢ï¼ˆå¤šæŸ¥è¯¢èåˆï¼‰
            start_time = time.time()
            docs_rewritten = self._multi_query_retrieval(
                rewritten_queries, 
                vector_store_manager, 
                k=5
            )
            time_rewritten = time.time() - start_time
            answer_rewritten = self._get_answer_from_docs(original_question, docs_rewritten, llm)
            
            result = {
                'original_question': original_question,
                'rewritten_queries': ' | '.join(rewritten_queries),
                'answer_original': answer_original,
                'answer_rewritten': answer_rewritten,
                'time_original': time_original,
                'time_rewritten': time_rewritten
            }
            results.append(result)
            
            print(f"  åŸå§‹æŸ¥è¯¢: {time_original:.2f}s")
            print(f"  æ”¹å†™æŸ¥è¯¢: {time_rewritten:.2f}s")
        
        # ä¿å­˜ç»“æœ
        df = pd.DataFrame(results)
        output_file = f'experiment_query_rewriting_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return df
    
    def _rewrite_query(self, query: str, llm, num_variants: int = 3) -> List[str]:
        """ä½¿ç”¨LLMæ”¹å†™æŸ¥è¯¢"""
        
        rewrite_prompt = ChatPromptTemplate.from_messages([
            ("system", f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·é—®é¢˜æ”¹å†™æˆ{num_variants}ä¸ªä¸åŒçš„ç‰ˆæœ¬ï¼Œä½¿å…¶æ›´é€‚åˆè¯­ä¹‰æœç´¢ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„
2. ä½¿ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼
3. æ·»åŠ ç›¸å…³å…³é”®è¯
4. ä½¿æŸ¥è¯¢æ›´å…·ä½“å’Œæ˜ç¡®

åªè¾“å‡ºæ”¹å†™åçš„é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªã€‚"""),
            ("human", "{query}")
        ])
        
        chain = rewrite_prompt | llm
        response = chain.invoke({"query": query})
        
        # è§£ææ”¹å†™ç»“æœ
        rewritten = [line.strip() for line in response.content.split('\n') if line.strip()]
        # ç§»é™¤åºå·
        rewritten = [q.split('.', 1)[-1].strip() if '.' in q[:5] else q for q in rewritten]
        
        return rewritten[:num_variants]
    
    def _multi_query_retrieval(self, queries: List[str], vector_store_manager, k: int = 4) -> List:
        """å¤šæŸ¥è¯¢èåˆæ£€ç´¢"""
        all_docs = []
        seen_content = set()
        
        # å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæ£€ç´¢
        for query in queries:
            docs = vector_store_manager.similarity_search(query, k=k)
            for doc in docs:
                # å»é‡
                if doc.page_content not in seen_content:
                    all_docs.append(doc)
                    seen_content.add(doc.page_content)
        
        # è¿”å›å‰kä¸ª
        return all_docs[:k]
    
    # ==================== ä¸»èœå• ====================
    
    def run_menu(self):
        """è¿è¡Œäº¤äº’å¼èœå•"""
        while True:
            print("\n" + "="*60)
            print("ğŸ”¬ RAGç³»ç»Ÿå®éªŒå¹³å°")
            print("="*60)
            print("\nè¯·é€‰æ‹©å®éªŒï¼š\n")
            print("  1. ğŸ“ å®éªŒ1: Chunk Sizeå¯¹æ¯”")
            print("  2. ğŸ”„ å®éªŒ2: Re-ranking (é‡æ’åº)")
            print("  3. âœï¸  å®éªŒ3: Query Rewriting (æŸ¥è¯¢æ”¹å†™)")
            print("  4. ğŸ¯ è¿è¡Œæ‰€æœ‰å®éªŒ")
            print("  5. âŒ é€€å‡º")
            print()
            
            choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()
            
            if choice == '1':
                self.experiment_chunk_size()
            elif choice == '2':
                self.experiment_reranking()
            elif choice == '3':
                self.experiment_query_rewriting()
            elif choice == '4':
                print("\nâ–¶ï¸  è¿è¡Œæ‰€æœ‰å®éªŒ...")
                self.experiment_chunk_size()
                self.experiment_reranking()
                self.experiment_query_rewriting()
                print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
            elif choice == '5':
                print("\nğŸ‘‹ å†è§ï¼")
                break
            else:
                print("\nâŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")
            
            if choice in ['1', '2', '3', '4']:
                input("\næŒ‰ Enter é”®ç»§ç»­...")


def main():
    """ä¸»å‡½æ•°"""
    experiments = RAGExperiments()
    experiments.run_menu()


if __name__ == "__main__":
    main()
